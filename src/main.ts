// src/main.ts

import { getLlama, LlamaChatSession } from "node-llama-cpp";
import { searchHistory, HistoryItem } from "./searchHistory.js";
import fs from "fs";

const query = "æˆ‘ä¹‹å‰çœ‹è¿‡å…³äº Web3 é’±åŒ…å®‰å…¨çš„æ–‡ç« ï¼Œæ˜¯å“ªä¸ªï¼Ÿ";

// mock ä¸€ä¸‹æµè§ˆè®°å½•ï¼Œæˆ–è€…ä»æ•°æ®åº“/æŠ“å–æ¨¡å—åŠ è½½
// const historyItems: HistoryItem[] = [
//   {
//     url: "https://example.com/web3-wallet-security",
//     title: "Web3 é’±åŒ…å®‰å…¨æŒ‡å—",
//     content: "è¿™ç¯‡æ–‡ç« ä»‹ç»äº† Web3 é’±åŒ…çš„ç§ç±»ã€å¸¸è§é£é™©ã€é˜²èŒƒæ–¹æ³•â€¦â€¦"
//   },
//   {
//     url: "https://news.com/ai-llms",
//     title: "æœ€æ–°å¤§æ¨¡å‹å‘å±•è¶‹åŠ¿",
//     content: "OpenAIã€Anthropicã€Mistral ç­‰å¤§æ¨¡å‹å…¬å¸æ­£åœ¨å¿«é€Ÿå‘å±•â€¦â€¦"
//   }
// ];

// ä»æ–‡ä»¶ä¸­è¯»å–å†å²è®°å½•
const historyFilePath = "./history_content.json";
const historyItems: HistoryItem[] = JSON.parse(fs.readFileSync(historyFilePath, 'utf-8'));


async function main() {
  const llama = await getLlama();
  const model = await llama.loadModel({
    modelPath: "/Users/zoe/Documents/web3/ai-agent/zoe/eliza/agent/model.gguf",
  });

  console.log("ğŸ¤– æ¨¡å‹åŠ è½½å®Œæˆ");

  const context = await model.createContext();
  const session = new LlamaChatSession({
    contextSequence: context.getSequence()
  });
  console.log("ğŸ¤– ä¼šè¯åˆ›å»ºå®Œæˆ")
  console.log("ğŸ¤– æ­£åœ¨æœç´¢å†å²è®°å½•...");

  const result = await searchHistory(query, historyItems, session);
  console.log("ğŸ¤– æœç´¢ç»“æœ:\n", result);
}

main();
